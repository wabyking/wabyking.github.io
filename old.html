<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <meta http-equiv="Content-Style-Type" content="text/css">
  <title>Benyou Wang's Homepage</title>
  <meta name="Generator" content="Cocoa HTML Writer">
  <meta name="CocoaVersion" content="1671.6">
  <style type="text/css">
  .center {
  margin: auto;
  width: 80%;
  /*border: 3px solid green;*/
  padding: 10px;
}

</style>
</head>
<body class="center">
<h1 style="margin: 0.0px 0.0px 16.1px 60.8px; text-indent: -60.8px; line-height: 28.0px; font: 24.0px Times; color: #000000; -webkit-text-stroke: #000000"><b>Benyou Wang</b></h1>
<p >Mail:   wabyking@gmail.com</p>

<p >Currently, I am a third-year (the last year) Ph.D. student at the University of Padova, Italy. I aim to develop novel mathematically inspired and linguistically motivated formalism/models/innovation for language understanding, which can also apply to high-level applications. In my relatively short academic experience, one of my co-authored papers won the SIGIR best paper honorable mention reward in 2017, and another paper with sharing first-authorship received NAACL 2019 Best Explainable paper.  <br>
</p>


<p> I submit my thesis in Sep. 30th 2021. <a href="talks/PhD_Thesis_Draft.pdf" >Here</a> is a darft version. The defending will happan in Feb. 2022. I am  in the job market now, send me emails if you are interested.</p>


<p>  I am recently interested in NLP.  The popular NLP killer, i.e., pre-trained language models (PLMs) might be good in terms of effectiveness. However, it is still limited: 
<li> PLMs need more understanding and  could therefore be  improved in the right directions.</li>
<li> PLMs cannot solve more complicated problems e.g., involving reasoning. This will be challenging in recent 10 or more years.</li>
<li> PLMs are too big to deploy (time and space-consuming).  Tensor networks may help for time-efficient or space-efficient PLMs.</li>
<li> It is assumed that "the bigger the better" (see GPT 3). PLMs are too expensive to be enlarged. Can quantum computing help to build GPT 10? </li>
<li> Can PLMs help for other domains like biomedical problems? In the biomedical domain, there are many types of sequential tokens (e.g., DNA, proteins, disease codes) that could be trained with PLMs.</li>
</p>



<p ><b>News</b></p>
<ol class="ol1">
  <!-- <li >I am visiting Speech and Language Computing Group, Huawei Noah's Ark Lab, hosted by Lifeng Shang.</li> -->
  <li>Our paper titled  <a href="https://openreview.net/forum?id=vy9jsg8VyoG">"Word2Fun: Modelling Words as Functions for Diachronic Word Representation"</a> got accepted in NeurIPS 2021 with my supervisors Massimo and Emanuele. This introduces a new paradigm to model time-specific word embedding (e.g., imagining that word "president" in 2018 and 2021 generally refer to different people), with both theoretical advantages and empirical success. This is a kind of work that are smaller, better, and more interpretable.</li>
  <li>Our paper titled  <a href="https://openreview.net/forum?id=onxoVA9FxMw">"On position embeddings in BERT"</a> got accepted in ICLR 2021. Try <a href="https://google.com/search?q=position+embeddings" > searching "position embeddings" in Google </a>. </li>
  <li >Our paper titled  <a href="https://openreview.net/forum?id=Hke-WTVtwr">"encoding word order in complex embeddings"</a> got accepted with a <b>spotlight</b> representation in ICLR 2020 (acceptance rate 6%). <a href="https://github.com/iclr-complex-order/complex-order">Codes were already open-sourced.</a>. This is the first work for rotation-based position embeddings while the previous is translation-based. </li>
   <!-- <li ></li> -->
  <!-- <li >I was visiting  University of Montreal from Dec. 2019 to Feb. 2020, hosted by Prof. Jian-Yun Nie. Montreal is a nice city for life and research.</li> -->
  <!-- <li >I visited  University of Amsterdam for one week, hosted by Prof. Maarten de Rijke, to give a talk in the <a href="https://www.meetup.com/SEA-Search-Engines-Amsterdam/events/fxjbhryznbhc/"> Meetup Search Engines Amsterdam. </a> </li> -->
  <!-- <li >I was visiting DIKU IR Lab in University of Copenhagen from Sep. to Dec., 2019 hosted by Prof. Christina Lioma.</li> -->
  <li >We won the Best explainable NLP paper in NAACL 2019 with 1000 dollars, present our paper together with BERT authors (Best Long paper winner).</li>
  <li> I got Marie Curry Fellowship to rejoin academia. Thanks for the generous funding.</li>
  <li>Our book <推荐系统与深度学习> has been published, buy it in  <a href="https://item.jd.com/12477453.html"> JD </a> </li>
  <li >We (IRGAN) won the Best Paper  honorable mention reward in SIGIR 2019, one of the most-cited paper in SIGIR</li>


  <!-- <li >There is an open-sourced project called Ragu, targeting to smoothly generate fluent adversarial examples for text.</li> -->
  <!-- <li >I visited Tencent Quantum Lab, Tencent Cloud NLP team (Zhiwen Lab), Tianjin University and Toutiao Bytedance AI lab in June-July 2019.</li> -->
</ol>

<p ><b>Awards</b></p>
<ol class="ol1">
  <li ><a href="https://naacl2019.org/blog/best-papers/">NAACL 2019 Best Explainable NLP Paper</a></li>
  <li ><a href="http://sigir.org/sigir2017/program/awards/">SIGIR 2017 best paper award Honorable Mention</a></li>
  <li ><a href="http://www.quartz-itn.eu/people/esr/esr-2">Selected </a>as a Marie Curie Researcher of <a href="http://www.quartz-itn.eu/">Quantum Information Access and Retrieval Theory (QUARTZ)</a>, a fellowship for Early-stage Researcher, funded by the European Union's Horizon 2020 research and innovation program under the Marie Skłodowska-Curie grant agreement No. 721321</li>
  <!-- <li >International Collaboration Proposal Prize, 2019 Joint Statistics Summer School by Univeristy of Bolzano, Padova and Salzburg</li> -->
</ol>

<h3 style="margin: 0.0px 0.0px 0.0px 0.0px; line-height: 17.0px; font: 14.0px Times; color: #000000; -webkit-text-stroke: #000000"><b>Education</b></h3>
<ul class="ul1">
  <li >2018.10-~:  Ph.D student:  information engineering,      University of Padua, Italy.</li>
  <li >2014.9-2017.2:  Master:  pattern recognition and intelligent system,      Tianjin University, China.</li>
  <li >2010.9-2014.6:  Bachelor:  software engineer,      Hubei University of Automotive Technology, China.</li>
</ul>

<h3 style="margin: 0.0px 0.0px 0.0px 0.0px; line-height: 17.0px; font: 14.0px Times; color: #000000; -webkit-text-stroke: #000000"><b>Work and Intern</b></h3>
<ul class="ul1">
  <li >2018.6-~:  Marie Curie Researcher, Department of Information Engineering, University of Padua, Italy. </li>
  <li >2020.12:  Visiting Scholar. Institute of Theoretical Physics, Chinese Academy of Science (CAS) in Dec. 2020 hosted by Pan Zhang </li>
  <li >2019.11-2020-2:  Visiting Student.  University of Montreal from Dec. 2019 to Feb. 2020, hosted by Prof. Jian-Yun Nie. </li>
  <li >2019.10:  Visiting Student (one week).  University of Amsterdam, hosted by Prof. Maarten de Rijke. </a> </li>
  <li >2019.9-2019.12:  Visiting Student.  DIKU IR Lab in University of Copenhagen, hosted by Prof. Christina Lioma. </li>
  <li >2017.7-2018.6:  Full-time Associate Researcher, Data Application Center, Tencent, China. </li>
  <!-- <li >2017.5-2017.7:  Research Consultant, Input method group, Sougou, China.</li> -->
  <li >2017.2-2017.5:  Research Assistant, Laboratory of Cognitive Computing and Application, Tianjin University.</li>
  <li >2015.8--2015.9 &amp; 2016.4-2016.5  Research Intern, <a href="http://ling.cass.cn/">Institute of Linguistics </a>, <a href="http://casseng.cssn.cn/">China Academy of Social Sciences </a>Beijing, China.</li>
</ul>

<h3 style="margin: 0.0px 0.0px 0.0px 0.0px; line-height: 17.0px; font: 14.0px Times; color: #000000; -webkit-text-stroke: #000000"><b>Professional Activities</b></h3>
<ul class="ul1">
  <li > PC member of  <a href="https://diacr-ita.github.io/DIACR-Ita/">  the workshop of Diachronic Lexical Semantics  evaluation task  </a>  in  <a href="http://www.evalita.it/2020/"> the 7th evaluation campaign of Natural Language Processing and Speech tools for Italian</a>  </li>
  <li > PC member of  <a href="https://www.aclweb.org/anthology/2020.eval4nlp-1.0.pdf"> the First Workshop  Evaluation and Comparison of NLP Systems in EMNLP 2020</a>  </li>
  <li > We co-organized <a href="kingmon_workshop.html"> the Kingston-Montreal NLP/IR workshop </a>  between researchers in RALI lab, University of Montreal and Queen's University. </li>
  <li >Founding member of Quantum Penguin Club in Tencent, the predecessor of Tencent Quantum Lab.</li>
  <li >Serveing as an Executive Committee of <a href="http://www.ccf.org.cn/">CCF (China computer Federation) </a>Tianjin University Branch in 2015-2016. I am responsible for inviting scholars for academic communication.</li>
  <li >Reviewer : ICLR 2021/2020, NeurIPS 2020</li>
  <!-- <li >Attendied conference: ACL 2019, SIGIR 2019, WWW 2019, NAACL 2019, ICML 2018, IJCAI 2018, CIKM 2018, ICTIR 2018</li> -->
</ul>

<h3 style="margin: 0.0px 0.0px 0.0px 0.0px; line-height: 17.0px; font: 14.0px Times; color: #0000e3; -webkit-text-stroke: #0000e3"><b><a href="publications.html" target="_blank">Publications </b><a href="https://scholar.google.com/citations?user=Jk4vJU8AAAAJ"><b>@ Google Scholar</b></a><b> </b></h3>

<ol class="ol1">
  <li > <b>Benyou Wang</b>, Emanuele Di Buiccio, Massimo Melucci. <a href="https://openreview.net/forum?id=vy9jsg8VyoG4"> Word2fun, modeling words as functions for dynamic word embeddings. </a>   <b>NeurIPS 2021, </b>. </li>
  <li > <b>Benyou Wang</b>, Lifeng Shang, Christina Lioma, Xin Jiang, Qun Liu, Jakob Grue Simonsen.<a href="https://openreview.net/forum?id=onxoVA9FxMw"> On position embeddings in BERT.</a>  <b>ICLR 2020, </b> </li>
  <li > <b>Benyou Wang</b>*, Donghao Zhao*, Christina Lioma, Qiuchi Li, Peng Zhang, Jakob Grue Simonsen. Encoding word order in complex embeddings. <b>ICLR 2019, </b><a href="https://openreview.net/forum?id=Hke-WTVtwr", style="color: red"><b>Spotlight paper</b></a> (acceptance rate: 6%) </li>
  <li >Qiuchi Li*, <b>Benyou Wang</b>*, Massimo Melucci. A Complex-valued Network for Matching. <b>NAACL 2019, </b><a href="https://naacl2019.org/blog/best-papers/" style="color: red"><b>Best Explainable NLP Paper</b></a></li>
  <li ><b></b><b>Benyou Wang</b>. Dynamic content monitoring and exploration using vector spaces. <b>SIGIR 2019 </b>doctoral consortium. </li>
  <li ><b></b><b>Benyou Wang</b>*, Qiuchi Li*, Massimo Melucci, Dawei Song. <a href="papers/www2019.pdf">Semantic Hilbert Space for Text Representation Learning.</a> <b>WWW 2019</b></li>
  <li >Wei Zhao*, <b>Benyou Wang</b>*, Min Yang, Jianbo Ye, Zhou Zhao, Xiaojun Chen, Ying Shen.. <a href="papers/toc.pdf">Leveraging Long and Short-term Information in Content-aware Movie Recommendation via Adversarial Training.</a> <b>IEEE Transactions on Cybernetics (TOC), 2019</b> (IF: 8.803)</li>
 
  <li >Peng Zhang, Zhan Su, Lipeng Zhang, <b>Benyou Wang </b>, Dawei Song. 2018. <a href="papers/QMBF.pdf">A Quantum Many-body Wave Function Inspired Language Modeling Approach.</a> <b>CIKM 2018</b></li>


  <li >Wei Zhao, <b>Wang Benyou </b>, Jianbo Ye, Yongqiang Gao, Min Yang, Xiaojun Chen, PLASTIC: Prioritize Long and Short-term Information in Top-n Recommendation using Adversarial Training, <b>IJCAI 2018</b></li>
  <li >Wei Zhao, <b>Wang Benyou </b>, Jianbo Ye, Min Yang, Zhou Zhao, Ruotian Luo, Yu Qiao A Multi-task Learning Approach for Image Captioning, <b>IJCAI 2018</b></li>
  
  <li >Zhang Peng, Niu Jiabing, Su Zhan, <b>Wang Benyou </b>et al. <a href="papers/aaai-2018.pdf">End-to-End Quantum-like Language Models with Application to Question Answering </a><b>AAAI 2018 </b></li>


  <li >Wang Jun, Yu Lantao, Zhang Weinan, Gong Yu, Xu Yinghui, <b>Wang Benyou</b> , Zhang Peng, Zhang Dell. <a href="https://arxiv.org/pdf/1705.10513.pdf">IRGAN: A Minimax Game for Unifying Generative and Discriminative Information Retrieval Models. </a><b>SIGIR 2017. </b><a href="http://sigir.org/sigir2017/program/awards/" style="color: red"><b>Best Paper Award Honourable Mentions</b><b> </b></a>. <a href="https://zhuanlan.zhihu.com/p/27297452">Zhihu link (in Chinses)</a></li>


  <li ><b></b><b>Wang Benyou</b>, Niu Jiabing, Ma Liqun, Zhang Yuhua, Zhang Lipeng, Li Jinfei, Zhang Peng Song, D. . <a href="https://link.springer.com/chapter/10.1007/978-3-319-50496-4_88">A Chinese Question Answering Approach Integrating Count-Based and Embedding-Based Features. </a>ICCPOL-NLPCC . December, 2016</li>
  <li ><b></b><b>Wang Benyou</b>, Zhang Peng, Li Jinfei, Song Dawei, Hou Yuexian, Shang Zhenguo. <a href="http://www.mdpi.com/1099-4300/18/4/144/pdf">Exploration of quantum interference in document relevance judgement discrepancy. </a><b>Entropy</b> , 18(4), 144. 2016. (IF : 1.821)</li>


  <li >Chen Yongqiang, Zhang Peng, Song Dawei, <b>Wang Benyou</b>. <a href="https://dl.acm.org/citation.cfm?id=2806602">A Real-Time Eye Tracking Based Query Expansion Approach via Latent Topic Modeling. </a><b>CIKM 2015 </b>(pp. 1719-1722). ACM. October, 2015</li>
</ol>
<h4 style="margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; line-height: 14.0px; font: 12.0px Times; color: #000000; -webkit-text-stroke: #000000"><b>Book and book chapter</b></h4>
<ol class="ol1">
  <li >Huang Xin, Wei zhao, <b>Wang Benyou</b>, Rui Zhao. Recommendation System and Deep Learning, Tsinghua University Press, in Chinese. Focusing on the chapters related "Learn to rank" and "Generative Adversarial Nets(GAN) for Recommendation". Online purchase link: <a href="https://item.jd.com/12477453.html">JD</a> and <a href="http://product.dangdang.com/26439080.html">Dangdang</a>. </li>
  <li ><b></b><b>Wang,B. </b>, Emanuele Di, B., &amp; Melucci, M.. <a href="papers/Wang2019_Chapter_RepresentingWordsInVectorSpace.pdf">  Representing words in vector space and beyond </a>. In A. Diederik, K. Andrei, M. Massimo, &amp; T. Bourama (Eds.),Quantum-like models forinformation retrieval and decision-making. Springer. </li>
</ol>

<h3 style="margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; line-height: 17.0px; font: 14.0px Times; color: #000000; -webkit-text-stroke: #000000"><b>Talks</b></h3>
<ol class="ol1">
    <li ><a href="talks/iir2021_slides.pdf"> Sequencial Modeling in Vector Spaces</a>, the Italian Information Retreival Workshop, in Sep 2021</li>
    <li ><a href="#"> On Position embeddings </a>, the China Student Symposium on NLP (CSSNLP), Beijing, in December,  2020</li>
    <li ><a href="#"> Invited lecture: Quantum theory and NLP </a>,  for bachelor  students, Beijing Institute of Technolohy, Beijing, in December,  2020</li>
    <li ><a href="#"> Invited lecture: pretrained language model and its position embeddings </a> for bachelor  students, Shandong University, Qingdao, in Dec.  2020</li>
    <li ><a href="#"> How physics and NLP help each other? </a>, <a href="http://english.itp.cas.cn/au/">  Institute of theoretical Physics, Chinese Academy of Science (CAS)  </a> Beijing, in December,  2020</li>
    <li ><a href=""> On Position embeddings </a>, Alibaba, Beijing in December,  2020</li>
    <li ><a href="talks/UNIPD@DIACR-Ita.pdf"></a>, Formulizing semantic shift detection as a distance between sets<a href="http://ceur-ws.org/Vol-2765/"> EVALITA 2020. Seventh Evaluation Campaign of Natural Language Processing and Speech Tools for Italian</a> <a href="https://diacr-ita.github.io/DIACR-Ita/">  Diachronic Lexical Semantics  </a>  online, on December 17th  2020</li>
    <li ><a href="talks/QCAI-QCAI.pdf">How quantum theory contributes to NLP</a>, <a href="https://qcai2020.gitee.io/"> First workshop of quantum computing and AI</a>,  virtually, previously in Tianjin University, Tianjin, China, 22. Nov. 2020</li>
    <li ><a href="talks/noah-talk.pdf">Encoding word order in complex embeddings</a>, <a href="http://www.noahlab.com.hk/#/home"> Speech and Language Computing Group, Huawei Noah's Ark Lab</a>, Shenzhen, China, 23. April 2020</li>
  <li ><a href="talks/quartz-uk.pdf">Dynamic Content Monitoring and Exploration using Vector Spaces</a>, <a href="https://www.beds.ac.uk/howtoapply/departments/computing"> University of Bedfordshire</a>, Luton, Lonton, UK, 12 Feb. 2020</li>
  <li ><a href="talks/uk-meetup.pdf">Quantum Mechanics meet Information Search and Retrieval – The QUARTZ Project</a>, <a href="https://www.meetup.com/textanalytics/"> Great London Text Analytics meetup</a>, London, UK, 12. Feb. 2020</li>
  <li ><a href="talks/mila-talk.pdf">Investigating complex-valued representation in NLP</a>, <a href="https://mila.quebec/en/"> Mila</a>, Mila, Montreal, Canada, 20. Jan 2020</li>
  <li ><a href="talks/montreal-talk.pdf">Beyond particles: modeling words as waves </a>, <a href="http://rali.iro.umontreal.ca/rali"> RALI Département d’informatique et recherche opérationnelle</a>, University of Montreal, Montreal, Canada, Dec. 7th 2019</li>
  <li ><a href="talks/cph-talk.pdf">Beyond particles: modeling words as waves </a>, <a href="https://di.ku.dk/english/research/machine-learning/"> DIKU machine learning section</a>, University of Copenhagen, Copenhagen, Denmark, Nov. 25th 2019</li>
  <li ><a href="talks/ams-talk-short.pdf">Quantum formulations for language: understand words as particles </a>, <a href="https://www.meetup.com/SEA-Search-Engines-Amsterdam/events/fxjbhryznbhc/"> meetup Search Engines Amsterdam </a>, University of Amsterdam, Amsterdam. Netherlands, Oct. 25th 2019</li>
  <li ><a href="talks/sigir-dc-final.pdf">Dynamic Content Monitoring and Exploration using Vector Spaces </a>, SIGIR Doctoral Consortium, Paris, France. July, 2019</li>
  <li >2019 Joint Statistics Summer School by Univeristy of Bolzano, Padova and Salzburg, Brixen, Italy. July 11, 2019</li>
  <li ><a href="talks/toutiao.pdf"> Quantum-inspired NLP/IR </a>. Bytedance AI Lab, Hang Li's group, Beijing, China. June 28, 2019</li>
  <li >Quantum-inspired NLP/IR. Tencent Cloud NLP team (Zhiwen Lab), Shenzhen, China, June 21, 2019</li>
  <li ><a href="talks/quantumNLP.pdf">Representing and interpreting words in vector space inspired by Quantum theory.</a> Quartz Workshop, University of Copenhagen</li>
  <li ><a href="talks/DL_tensor.pdf">Tensor analysis for DL.</a> Functional Analysis, University of Padova</li>
  <li ><a href="talks/embeddingBeyond.pdf">Word embedding and the beyond.</a>> IR group, University of Padova</li>
  <li ><a href="talks/DL.pdf">Deep Learning in language</a> : offline workshop in Padova </li>
  <li ><a href="talks/discussion.pdf">Research discussion</a> : Quartz project, University of Padova, Italy, 2018 Oct. </li>
  <li ><a href="talks/quartz_mid_improved.pdf">Individual Research Project for Quartz</a> : Quartz project, University of Padova, Italy, 2018 Oct. </li>
  <li ><a href="talks/quartz_qnn.pdf">Interpretable Neural network driven byquantum probability theory</a> : Quartz project, Germany. 2018 Sep. </li>
  <li ><a href="talks/tju.pdf">Exploring Interpretable Quantum Representation for language understanding</a> : Tianjin University, China. 2018 Sep. </li>
  <li ><a href="talks/tencent.pdf">Exploring Interpretable Quantum Representation for language understanding</a> : Tencent, China. 2018 Sep. </li>
  <li ><a href="talks/QuantumInterpretableNN.pdf">Exploring Interpretable Neural Network by Quantum representation</a> : Quartz workshop in Iatly, Padova. 2018 Sep. </li>
  <li ><a href="talks/overview.pdf">Representations and their matching: an overview of my previous research</a> : Padova, Italy. 2018.7 </li>
  <li ><a href="talks/textzoo.pdf">TextZOO, a new Benchmark to Reconsidering Text Classification</a> : Data Center, SNG, Tencent, Shenzhen, China. 2018.3.29 </li>
  <li ><a href="talks/nnqlm.pdf">Neural Network based Quantum Language Model for QA</a> : "AAAI 2018 Spotlights Proseminar ", Tencent, Shenzhen, China. 2018.3.28 </li>
  <li ><a href="talks/quantumnn.pdf">Quantum-inspired Neural Network</a> : <a href="http://www.quartz-itn.eu/training/winter-school">Quartz Winter School 2018 </a>, Padova, Italy 2018.2.14</li>
  <li ><a href="talks/chatbot.pdf">ChatBot in DSNO </a>: Apartment of product for instant communication, SNG, Tencent, Shenzhen, China. </li>
  <li ><a href="talks/quantumqa.pdf">Quantum Language Model for QA </a>: Quantum Penguin, Tencent, to be appeared </li>
  <li >Detail of our ChatBot : Apartment of product for instant communication, SNG, Tencent </li>
  <li >Progress of our ChatBot : the only non-leader 15-min Speaker in Center of Data Application, SNG, Tencent </li>
</ol>
<h3 style="margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; line-height: 17.0px; font: 14.0px Times; color: #000000; -webkit-text-stroke: #000000"><b>Industrial Projects</b></h3>
<ol class="ol1">
  <li ><a href="https://cloud.tencent.com/product/xiaowei">Chatbot: Customer Service Robot </a>in Tencent Cloud. 2017. With many traditional IR (information retrieval ) practice and deep learning application. I am the main designer and coder of the second generation customer service in Tencent Cloud, which has served more than 50 enterprises e.g. The Bank of China, Travel Bureau in Yunnan province, WeBank and Xinren Doctor.</li>
  <li >Modelling short-term interest user-profile for <a href="https://qzone.qq.com/">Qzone short </a>vedio recommendation.</li>
  <li >CNN-based language model in <a href="https://www.sogou.com/">Sogou</a> <a href="https://pinyin.sogou.com/">input method</a>, the most popular Chinese Input Method. </li>
</ol>
<h3 style="margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; line-height: 17.0px; font: 14.0px Times; color: #000000; -webkit-text-stroke: #000000"><b>Open-Source code</b></h3>
<ol class="ol1">
  <li ><a href="https://github.com/iclr-complex-order/complex-order">Word Wave</a>, Encoding word order in complex embeddings. </li>
  <li ><a href="https://github.com/wabyking/qnn">CNM</a>, Complex-valued neural network for NLP. </li>
  <li ><a href="https://github.com/geek-ai/irgan">IRGAN</a>, Generative Adversarial Nets for Question Answering. <a href="https://github.com/wabyking/IRGAN-AnswerSelection">A cleaner version</a> </li>
  <li ><a href="https://github.com/wabyking/TextClassificationBenchmarkInPytorch">TextZoo</a>, a new Text Classification Benchmark in PyTorch : in progress</li>
  <li ><a href="https://github.com/TJUIRLAB/NNQLM">NNQLM</a>, an End2end Quantum Language Model for Question Answering in Theano version. <a href="https://github.com/shuishen112/quantum-qa">Tensorflow version</a> </li>
  <li ><a href="https://github.com/wabyking/PyQLM">PyQLM </a>, A lightweight python project to implement Quantum Language model.</li>
  <li ><a href="https://github.com/wabyking/QuantumAttentionLSTM">QALSTM</a>, a LSTM with a Quantum parameter-free attention, in Theano.</li>
  <li ><a href="https://github.com/complexembedding/complex_word_embedding">CWE</a>, Complex word embedding, in Keras.</li>
  <li ><a href="https://github.com/wabyking/Gated_CNN_for_language_Modeling">CNN Language Model </a>, multi-GPU version in TensorFlow.</li>
</ol>
<h3 style="margin: 0.0px 0.0px 0.0px 0.0px; text-align: justify; line-height: 17.0px; font: 14.0px Times; color: #000000; -webkit-text-stroke: #000000"><b>Co-supervised Junior Students</b></h3>
<ol class="ol1">
  <li >Mr. Niu Jiabing in Tianjin University. (now in Mobvoi)</li>
  <li >Miss. Zhang Shengnan in Tianjin University. (now in Toutiao)</li>
  <li >Miss. Niu Xiaolei in Tianjin University. (now in China mobile research institution)</li>
  <li >Mr. Su Zhan in Tianjin University. (now in Tencent)</li>
  <li >Mr. Zhang Lipeng in Tianjin University. (now in Hikvision research institution)</li>
  <li >Mr. Liqun Ma in Tianjin University. (now in Shenzhen Institutes of Advanced Technology (SIAT), Chinese Academy of Sciences)</li>
  <li >Mr. Donghao Zhao in Tianjin University. </li>
  <li >Miss. Xiaoliu Mao in Tianjin University. </li>
</ol>
</body>
</html>
